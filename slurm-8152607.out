The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) 2023.01   2) StdEnv
Batches in train_dataloder: 3311
Batches in val_dataloder: 414
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:04<?, ?it/s]
Traceback (most recent call last):
  File "/home4/s4362675/DLProject/train_local.py", line 51, in <module>
    y_pred = model(X)
  File "/home4/s4362675/env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home4/s4362675/env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home4/s4362675/DLProject/transformer.py", line 131, in forward
    dec_outputs = self.decoder_stack(x)
  File "/home4/s4362675/env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home4/s4362675/env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home4/s4362675/DLProject/transformer.py", line 100, in forward
    decoder_output = layer(decoder_output, position_embeddings)
  File "/home4/s4362675/env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home4/s4362675/env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home4/s4362675/DLProject/transformer.py", line 58, in forward
    attn_out = self.norm(self.dropout_1(self.aft(embedding, embedding, embedding)) + embedding)
  File "/home4/s4362675/env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home4/s4362675/env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home4/s4362675/DLProject/aft.py", line 77, in forward
    masked_K = torch.where(window_mask, masked_K, torch.zeros_like(masked_K))
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!

###############################################################################
H치br칩k Cluster
Job 8152607 for user s4362675
Finished at: Sat Apr 13 23:04:47 CEST 2024

Job details:
============

Job ID              : 8152607
Name                : aft_local
User                : s4362675
Partition           : gpumedium
Nodes               : v100gpu23
Number of Nodes     : 1
Cores               : 8
Number of Tasks     : 1
State               : RUNNING
Submit              : 2024-04-13T21:54:56
Start               : 2024-04-13T23:03:36
End                 : --
Reserved walltime   : 12:00:00
Used walltime       : 00:01:11
Used CPU time       : --
% User (Computation): --
% System (I/O)      : --
Mem reserved        : 8000M
Max Mem (Node/step) : 0.00  (Node unknown, N/A)
Full Max Mem usage  : 0.00  (Until last completed step)
Total Disk Read     : 0.00  (Until last completed step)
Total Disk Write    : 0.00  (Until last completed step)

Acknowledgements:
=================

Please see this page for information about acknowledging H치br칩k in your publications:

https://wiki.hpc.rug.nl/habrok/introduction/scientific_output

################################################################################
